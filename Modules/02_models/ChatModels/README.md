# üí¨ Understanding Chat Models in LangChain
Chat models are designed specifically for **multi-turn, conversational interactions**. They‚Äôre ideal for applications like chatbots, virtual assistants, AI tutors, or anything requiring dynamic, context-aware dialogue.
This section of the course will help you understand how LangChain works with chat models across different providers, and how you can build intelligent, interactive agents with minimal code.

---

## üîß How LangChain Handles Chat Models

LangChain provides a high-level interface for working with chat models through its `ChatModel` classes like `ChatOpenAI`, `ChatAnthropic`, and others.
Instead of writing plain prompts, you build conversations using LangChain's message classes:

- `system` messages ‚Äì for setting behavior and context  
- `user` messages ‚Äì representing input from the user  
- `assistant` messages ‚Äì generated by the model in response

This structure allows chat models to better understand the context of a conversation and generate more coherent, relevant responses.

---
## üîß How LangChain Handles Chat Models

LangChain provides the `ChatModel` interface (e.g., `ChatOpenAI`, `ChatAnthropic`, etc.) that simplifies how you interact with these providers. Instead of crafting raw prompts, you send messages using LangChain‚Äôs `HumanMessage`, `AIMessage`, and `SystemMessage`.

Example:
```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

chat = ChatOpenAI()
messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="What's the capital of France?")
]
response = chat(messages)
print(response.content)
```
## üìÅ Folder Structure & Examples

This folder contains implementations using different chat model providers:

| File                      | Description                                                       |
|---------------------------|-------------------------------------------------------------------|
| [`openai_chat_model.py`](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/openai_chat_model.py)    | Using OpenAI‚Äôs ChatGPT models with LangChain                     |
| [`huggingface_chat_model.py`](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/huggingface_chat_model.py) | Example using Hugging Face‚Äôs chat-compatible models             |
| [`local_llama_chat_model.py`](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/local_llama_chat_model.py) | Running a local LLaMA-based chat model with LangChain          |
| [`anthropic_chat_model.py`](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/anthropic_chat_model.py) | Integration with Anthropic's Claude via ChatAnthropic            |
| [`streamlit_chatbot.py`](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/streamlit_chatbot.py)    | Streamlit-powered UI for an interactive chatbot                  |

---
### üåê  Providers Covered
[OpenAI (ChatGPT)](https://platform.openai.com/docs/overview)
- Widely used for general-purpose conversational AI.
- Supports message roles and advanced control.
- OpenAI API Docs
  
[Hugging Face](https://huggingface.co/)
- Access open-source chat models like Mistral, Falcon, or ChatGLM.
- Can run locally (via Transformers) or use Hugging Face Inference API.
- Great for customizing and experimenting with different architectures
  
[Local LLaMA](https://ollama.com/)
- Run models on your own hardware for privacy, speed, or offline use.
- Ideal for edge devices or controlled environments.
- Often used with quantized versions for better performance on CPUs.

[Anthropic (Claude)](https://claude.ai/login)
- Claude is designed for safer and more human-aligned conversations.
- LangChain integrates Claude using the `ChatAnthropic` wrapper.
- Great for sensitive applications or enterprise deployments.


---
### üíª Streamlit Chatbot Interface
The [streamlit_chatbot.py](https://github.com/Adity-star/LangChainMastery/blob/main/Modules/02_models/ChatModels/streamlit_chatbot.py)script provides a ready-to-run Streamlit app for chatting with your selected model.

To run it:
```bash
streamlit run streamlit_chatbot.py
```
You can modify the script to switch models, customize the system prompt, or connect it with tools like vector stores and memory.

### Want to Contribute?
Feel free to open issues, submit PRs, or suggest new providers and examples. Whether you're improving documentation or adding new integrations, contributions are always welcome!

---

### Next Steps 
Now that you‚Äôve learned how to work with **Chat Models**, it‚Äôs time to explore how **embedding models** are used to enable *search*, *retrieval*, *similarity*, and *context-aware reasoning*.

Ready for next step? Let's go [**Embedding Models**](https://github.com/Adity-star/LangChainMastery/tree/main/Modules/02_models/EmbeddingModels)
